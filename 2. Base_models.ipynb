{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code for the following steps:\n",
    "- training of standard classifiers\n",
    "- selection of parameters according to f1 scoring\n",
    "- collection of metrics for each binarization strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To comply with the code style\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3v12S4V2u8J0"
   },
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dUEvmHBsu8J0"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin_strategy1 = pd.read_csv(\"datasets/strategy1.csv\", index_col=0)\n",
    "df_bin_strategy2 = pd.read_csv(\"datasets/strategy2.csv\", index_col=0)\n",
    "df_bin_strategy3 = pd.read_csv(\"datasets/strategy3.csv\", index_col=0)\n",
    "df_bin_strategy4 = pd.read_csv(\"datasets/strategy4.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgvmQkGnu8J6"
   },
   "source": [
    "### Spliting the data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updated_split(df):\n",
    "    y = df[\"stroke\"]\n",
    "    X = df.drop(columns=[\"stroke\"])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=SEED\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = updated_split(df_bin_strategy1)\n",
    "X_train2, X_test2, y_train2, y_test2 = updated_split(df_bin_strategy2)\n",
    "X_train3, X_test3, y_train3, y_test3 = updated_split(df_bin_strategy3)\n",
    "X_train4, X_test4, y_train4, y_test4 = updated_split(df_bin_strategy4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obxf3WTzu8J6"
   },
   "source": [
    "# Base models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xo2VX5mST_yr"
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"kNN\": KNeighborsClassifier(n_jobs=-1),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        multi_class=\"ovr\",\n",
    "        solver=\"saga\",\n",
    "        n_jobs=-1,\n",
    "        random_state=SEED,\n",
    "    ),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=SEED),\n",
    "    \"Random Forest\": RandomForestClassifier(n_jobs=-1, random_state=SEED),\n",
    "    \"CatBoost\": CatBoostClassifier(\n",
    "        allow_writing_files=False, verbose=0, random_state=SEED\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(n_jobs=-1, random_state=SEED),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"kNN\": {\"n_neighbors\": [3, 5, 7], \"weights\": [\"uniform\", \"distance\"]},\n",
    "    \"Naive Bayes\": {},\n",
    "    \"Logistic Regression\": {\n",
    "        \"penalty\": [None, \"l1\", \"l2\"],\n",
    "        \"tol\": [1e-4, 1e-3, 1e-2],\n",
    "        \"max_iter\": [100, 500, 1000],\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [50, 100, 500],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "        \"min_samples_split\": [2, 5, 7],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        \"learning_rate\": [1e-3, 1e-2, 1e-1],\n",
    "        \"n_estimators\": [100, 500, 700],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"learning_rate\": [1e-3, 1e-2, 1e-1],\n",
    "        \"n_estimators\": [100, 500, 700],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"classifier\": [],\n",
    "    \"best_parameters\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1_score\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(name, classifier, param_grid, X_train, X_test, y_train, y_test, results):\n",
    "    # Cross-validation and parameter tuning for each classifier\n",
    "    print(f\"{name} Classifier\")\n",
    "    results[\"classifier\"].append(name)\n",
    "\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv=3, scoring=\"f1\", n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    results[\"best_parameters\"].append(best_params)\n",
    "\n",
    "    best_clf = grid_search.best_estimator_\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "\n",
    "    # Store metric\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"precision\"].append(prec)\n",
    "    results[\"recall\"].append(rec)\n",
    "    results[\"f1_score\"].append(f1)\n",
    "\n",
    "    print(\"Best Parameters:\")\n",
    "    print(best_params)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_train, X_test, y_train, y_test):\n",
    "    results = {\n",
    "        \"classifier\": [],\n",
    "        \"best_parameters\": [],\n",
    "        \"accuracy\": [],\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": [],\n",
    "    }\n",
    "    for name, clf in classifiers.items():\n",
    "        cv(name, clf, param_grid[name], X_train, X_test, y_train, y_test, results)\n",
    "    res = pd.DataFrame(results)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First strategy: seemingly logical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Classifier\n",
      "Best Parameters:\n",
      "{'n_neighbors': 7, 'weights': 'uniform'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78        95\n",
      "           1       0.55      0.55      0.55        47\n",
      "\n",
      "    accuracy                           0.70       142\n",
      "   macro avg       0.67      0.67      0.67       142\n",
      "weighted avg       0.70      0.70      0.70       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Best Parameters:\n",
      "{}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.56      0.72        95\n",
      "           1       0.53      1.00      0.69        47\n",
      "\n",
      "    accuracy                           0.70       142\n",
      "   macro avg       0.76      0.78      0.70       142\n",
      "weighted avg       0.84      0.70      0.71       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Logistic Regression Classifier\n",
      "Best Parameters:\n",
      "{'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81        95\n",
      "           1       0.62      0.51      0.56        47\n",
      "\n",
      "    accuracy                           0.73       142\n",
      "   macro avg       0.70      0.68      0.68       142\n",
      "weighted avg       0.72      0.73      0.73       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Decision Tree Classifier\n",
      "Best Parameters:\n",
      "{'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79        95\n",
      "           1       0.58      0.53      0.56        47\n",
      "\n",
      "    accuracy                           0.72       142\n",
      "   macro avg       0.68      0.67      0.67       142\n",
      "weighted avg       0.71      0.72      0.71       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Random Forest Classifier\n",
      "Best Parameters:\n",
      "{'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82        95\n",
      "           1       0.64      0.53      0.58        47\n",
      "\n",
      "    accuracy                           0.75       142\n",
      "   macro avg       0.71      0.69      0.70       142\n",
      "weighted avg       0.74      0.75      0.74       142\n",
      "\n",
      "----------------\n",
      "\n",
      "CatBoost Classifier\n",
      "Best Parameters:\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81        95\n",
      "           1       0.62      0.53      0.57        47\n",
      "\n",
      "    accuracy                           0.74       142\n",
      "   macro avg       0.70      0.69      0.69       142\n",
      "weighted avg       0.73      0.74      0.73       142\n",
      "\n",
      "----------------\n",
      "\n",
      "XGBoost Classifier\n",
      "Best Parameters:\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.81        95\n",
      "           1       0.61      0.53      0.57        47\n",
      "\n",
      "    accuracy                           0.73       142\n",
      "   macro avg       0.70      0.68      0.69       142\n",
      "weighted avg       0.73      0.73      0.73       142\n",
      "\n",
      "----------------\n",
      "\n",
      "CPU times: total: 10.5 s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res1 = evaluate(X_train1, X_test1, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>best_parameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.739809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.733583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.727367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.725354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.714954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'uniform'}</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            classifier  \\\n",
       "4        Random Forest   \n",
       "5             CatBoost   \n",
       "6              XGBoost   \n",
       "2  Logistic Regression   \n",
       "3        Decision Tree   \n",
       "1          Naive Bayes   \n",
       "0                  kNN   \n",
       "\n",
       "                                                                        best_parameters  \\\n",
       "4  {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}   \n",
       "5                          {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}   \n",
       "6                          {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}   \n",
       "2                                       {'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}   \n",
       "3                       {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}   \n",
       "1                                                                                    {}   \n",
       "0                                              {'n_neighbors': 7, 'weights': 'uniform'}   \n",
       "\n",
       "   accuracy  precision    recall  f1_score  \n",
       "4  0.746479   0.641026  0.531915  0.739809  \n",
       "5  0.739437   0.625000  0.531915  0.733583  \n",
       "6  0.732394   0.609756  0.531915  0.727367  \n",
       "2  0.732394   0.615385  0.510638  0.725354  \n",
       "3  0.718310   0.581395  0.531915  0.714954  \n",
       "1  0.704225   0.528090  1.000000  0.707928  \n",
       "0  0.704225   0.553191  0.553191  0.704225  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(res1.sort_values(by=\"f1_score\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.739809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.733583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.727367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.725354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.714954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            classifier  accuracy  precision    recall  f1_score\n",
       "4        Random Forest  0.746479   0.641026  0.531915  0.739809\n",
       "5             CatBoost  0.739437   0.625000  0.531915  0.733583\n",
       "6              XGBoost  0.732394   0.609756  0.531915  0.727367\n",
       "2  Logistic Regression  0.732394   0.615385  0.510638  0.725354\n",
       "3        Decision Tree  0.718310   0.581395  0.531915  0.714954\n",
       "1          Naive Bayes  0.704225   0.528090  1.000000  0.707928\n",
       "0                  kNN  0.704225   0.553191  0.553191  0.704225"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    res1[[\"classifier\", \"accuracy\", \"precision\", \"recall\", \"f1_score\"]].sort_values(\n",
    "        by=\"f1_score\", ascending=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second strategy: inter-ordinal for each numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Classifier\n",
      "Best Parameters:\n",
      "{'n_neighbors': 7, 'weights': 'uniform'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79        95\n",
      "           1       0.57      0.57      0.57        47\n",
      "\n",
      "    accuracy                           0.72       142\n",
      "   macro avg       0.68      0.68      0.68       142\n",
      "weighted avg       0.72      0.72      0.72       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Best Parameters:\n",
      "{}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.60      0.74        95\n",
      "           1       0.54      0.96      0.69        47\n",
      "\n",
      "    accuracy                           0.72       142\n",
      "   macro avg       0.75      0.78      0.72       142\n",
      "weighted avg       0.83      0.72      0.72       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Logistic Regression Classifier\n",
      "Best Parameters:\n",
      "{'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81        95\n",
      "           1       0.62      0.53      0.57        47\n",
      "\n",
      "    accuracy                           0.74       142\n",
      "   macro avg       0.70      0.69      0.69       142\n",
      "weighted avg       0.73      0.74      0.73       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Decision Tree Classifier\n",
      "Best Parameters:\n",
      "{'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79        95\n",
      "           1       0.58      0.53      0.56        47\n",
      "\n",
      "    accuracy                           0.72       142\n",
      "   macro avg       0.68      0.67      0.67       142\n",
      "weighted avg       0.71      0.72      0.71       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Random Forest Classifier\n",
      "Best Parameters:\n",
      "{'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        95\n",
      "           1       0.59      0.49      0.53        47\n",
      "\n",
      "    accuracy                           0.72       142\n",
      "   macro avg       0.68      0.66      0.67       142\n",
      "weighted avg       0.71      0.72      0.71       142\n",
      "\n",
      "----------------\n",
      "\n",
      "CatBoost Classifier\n",
      "Best Parameters:\n",
      "{'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81        95\n",
      "           1       0.61      0.57      0.59        47\n",
      "\n",
      "    accuracy                           0.74       142\n",
      "   macro avg       0.70      0.70      0.70       142\n",
      "weighted avg       0.74      0.74      0.74       142\n",
      "\n",
      "----------------\n",
      "\n",
      "XGBoost Classifier\n",
      "Best Parameters:\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        95\n",
      "           1       0.59      0.49      0.53        47\n",
      "\n",
      "    accuracy                           0.72       142\n",
      "   macro avg       0.68      0.66      0.67       142\n",
      "weighted avg       0.71      0.72      0.71       142\n",
      "\n",
      "----------------\n",
      "\n",
      "CPU times: total: 13.8 s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res2 = evaluate(X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>best_parameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.737167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.733583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.542169</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.724388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'uniform'}</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.714954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.710899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.710899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            classifier  \\\n",
       "5             CatBoost   \n",
       "2  Logistic Regression   \n",
       "1          Naive Bayes   \n",
       "0                  kNN   \n",
       "3        Decision Tree   \n",
       "4        Random Forest   \n",
       "6              XGBoost   \n",
       "\n",
       "                                                                       best_parameters  \\\n",
       "5                        {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}   \n",
       "2                                      {'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}   \n",
       "1                                                                                   {}   \n",
       "0                                             {'n_neighbors': 7, 'weights': 'uniform'}   \n",
       "3                      {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}   \n",
       "4  {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}   \n",
       "6                         {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}   \n",
       "\n",
       "   accuracy  precision    recall  f1_score  \n",
       "5  0.739437   0.613636  0.574468  0.737167  \n",
       "2  0.739437   0.625000  0.531915  0.733583  \n",
       "1  0.718310   0.542169  0.957447  0.724388  \n",
       "0  0.718310   0.574468  0.574468  0.718310  \n",
       "3  0.718310   0.581395  0.531915  0.714954  \n",
       "4  0.718310   0.589744  0.489362  0.710899  \n",
       "6  0.718310   0.589744  0.489362  0.710899  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(res2.sort_values(by=\"f1_score\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.737167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.733583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.542169</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.724388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.714954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.710899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.710899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            classifier  accuracy  precision    recall  f1_score\n",
       "5             CatBoost  0.739437   0.613636  0.574468  0.737167\n",
       "2  Logistic Regression  0.739437   0.625000  0.531915  0.733583\n",
       "1          Naive Bayes  0.718310   0.542169  0.957447  0.724388\n",
       "0                  kNN  0.718310   0.574468  0.574468  0.718310\n",
       "3        Decision Tree  0.718310   0.581395  0.531915  0.714954\n",
       "4        Random Forest  0.718310   0.589744  0.489362  0.710899\n",
       "6              XGBoost  0.718310   0.589744  0.489362  0.710899"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    res2[[\"classifier\", \"accuracy\", \"precision\", \"recall\", \"f1_score\"]].sort_values(\n",
    "        by=\"f1_score\", ascending=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third strategy: larger intervals for numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Classifier\n",
      "Best Parameters:\n",
      "{'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78        95\n",
      "           1       0.56      0.51      0.53        47\n",
      "\n",
      "    accuracy                           0.70       142\n",
      "   macro avg       0.66      0.66      0.66       142\n",
      "weighted avg       0.70      0.70      0.70       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Best Parameters:\n",
      "{}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.67      0.80        95\n",
      "           1       0.59      0.96      0.73        47\n",
      "\n",
      "    accuracy                           0.77       142\n",
      "   macro avg       0.78      0.82      0.76       142\n",
      "weighted avg       0.84      0.77      0.77       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Logistic Regression Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nasyk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "{'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81        95\n",
      "           1       0.62      0.53      0.57        47\n",
      "\n",
      "    accuracy                           0.74       142\n",
      "   macro avg       0.70      0.69      0.69       142\n",
      "weighted avg       0.73      0.74      0.73       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Decision Tree Classifier\n",
      "Best Parameters:\n",
      "{'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.81        95\n",
      "           1       0.61      0.47      0.53        47\n",
      "\n",
      "    accuracy                           0.73       142\n",
      "   macro avg       0.69      0.66      0.67       142\n",
      "weighted avg       0.71      0.73      0.71       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Random Forest Classifier\n",
      "Best Parameters:\n",
      "{'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82        95\n",
      "           1       0.63      0.55      0.59        47\n",
      "\n",
      "    accuracy                           0.75       142\n",
      "   macro avg       0.71      0.70      0.70       142\n",
      "weighted avg       0.74      0.75      0.74       142\n",
      "\n",
      "----------------\n",
      "\n",
      "CatBoost Classifier\n",
      "Best Parameters:\n",
      "{'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81        95\n",
      "           1       0.61      0.57      0.59        47\n",
      "\n",
      "    accuracy                           0.74       142\n",
      "   macro avg       0.70      0.70      0.70       142\n",
      "weighted avg       0.74      0.74      0.74       142\n",
      "\n",
      "----------------\n",
      "\n",
      "XGBoost Classifier\n",
      "Best Parameters:\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.81        95\n",
      "           1       0.61      0.53      0.57        47\n",
      "\n",
      "    accuracy                           0.73       142\n",
      "   macro avg       0.70      0.68      0.69       142\n",
      "weighted avg       0.73      0.73      0.73       142\n",
      "\n",
      "----------------\n",
      "\n",
      "CPU times: total: 13.4 s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res3 = evaluate(X_train3, X_test3, y_train3, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>best_parameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.767606</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.774072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.741717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.737167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.733583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.727367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}</td>\n",
       "      <td>0.725352</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.714668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'uniform'}</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.700702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            classifier  \\\n",
       "1          Naive Bayes   \n",
       "4        Random Forest   \n",
       "5             CatBoost   \n",
       "2  Logistic Regression   \n",
       "6              XGBoost   \n",
       "3        Decision Tree   \n",
       "0                  kNN   \n",
       "\n",
       "                                                                       best_parameters  \\\n",
       "1                                                                                   {}   \n",
       "4  {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}   \n",
       "5                        {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}   \n",
       "2                                    {'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}   \n",
       "6                         {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}   \n",
       "3                      {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}   \n",
       "0                                             {'n_neighbors': 5, 'weights': 'uniform'}   \n",
       "\n",
       "   accuracy  precision    recall  f1_score  \n",
       "1  0.767606   0.592105  0.957447  0.774072  \n",
       "4  0.746479   0.634146  0.553191  0.741717  \n",
       "5  0.739437   0.613636  0.574468  0.737167  \n",
       "2  0.739437   0.625000  0.531915  0.733583  \n",
       "6  0.732394   0.609756  0.531915  0.727367  \n",
       "3  0.725352   0.611111  0.468085  0.714668  \n",
       "0  0.704225   0.558140  0.510638  0.700702  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(res3.sort_values(by=\"f1_score\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.767606</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.774072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.741717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.737167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.733583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.727367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.725352</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.714668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.700702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            classifier  accuracy  precision    recall  f1_score\n",
       "1          Naive Bayes  0.767606   0.592105  0.957447  0.774072\n",
       "4        Random Forest  0.746479   0.634146  0.553191  0.741717\n",
       "5             CatBoost  0.739437   0.613636  0.574468  0.737167\n",
       "2  Logistic Regression  0.739437   0.625000  0.531915  0.733583\n",
       "6              XGBoost  0.732394   0.609756  0.531915  0.727367\n",
       "3        Decision Tree  0.725352   0.611111  0.468085  0.714668\n",
       "0                  kNN  0.704225   0.558140  0.510638  0.700702"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    res3[[\"classifier\", \"accuracy\", \"precision\", \"recall\", \"f1_score\"]].sort_values(\n",
    "        by=\"f1_score\", ascending=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth strategy: selecting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Classifier\n",
      "Best Parameters:\n",
      "{'n_neighbors': 7, 'weights': 'uniform'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80        95\n",
      "           1       0.60      0.53      0.56        47\n",
      "\n",
      "    accuracy                           0.73       142\n",
      "   macro avg       0.69      0.68      0.68       142\n",
      "weighted avg       0.72      0.73      0.72       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Best Parameters:\n",
      "{}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79        95\n",
      "           1       0.58      0.70      0.63        47\n",
      "\n",
      "    accuracy                           0.73       142\n",
      "   macro avg       0.71      0.72      0.71       142\n",
      "weighted avg       0.75      0.73      0.74       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Logistic Regression Classifier\n",
      "Best Parameters:\n",
      "{'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80        95\n",
      "           1       0.60      0.55      0.58        47\n",
      "\n",
      "    accuracy                           0.73       142\n",
      "   macro avg       0.70      0.69      0.69       142\n",
      "weighted avg       0.73      0.73      0.73       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Decision Tree Classifier\n",
      "Best Parameters:\n",
      "{'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.81        95\n",
      "           1       0.61      0.47      0.53        47\n",
      "\n",
      "    accuracy                           0.73       142\n",
      "   macro avg       0.69      0.66      0.67       142\n",
      "weighted avg       0.71      0.73      0.71       142\n",
      "\n",
      "----------------\n",
      "\n",
      "Random Forest Classifier\n",
      "Best Parameters:\n",
      "{'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81        95\n",
      "           1       0.61      0.57      0.59        47\n",
      "\n",
      "    accuracy                           0.74       142\n",
      "   macro avg       0.70      0.70      0.70       142\n",
      "weighted avg       0.74      0.74      0.74       142\n",
      "\n",
      "----------------\n",
      "\n",
      "CatBoost Classifier\n",
      "Best Parameters:\n",
      "{'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 500}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81        95\n",
      "           1       0.61      0.57      0.59        47\n",
      "\n",
      "    accuracy                           0.74       142\n",
      "   macro avg       0.70      0.70      0.70       142\n",
      "weighted avg       0.74      0.74      0.74       142\n",
      "\n",
      "----------------\n",
      "\n",
      "XGBoost Classifier\n",
      "Best Parameters:\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79        95\n",
      "           1       0.58      0.53      0.56        47\n",
      "\n",
      "    accuracy                           0.72       142\n",
      "   macro avg       0.68      0.67      0.67       142\n",
      "weighted avg       0.71      0.72      0.71       142\n",
      "\n",
      "----------------\n",
      "\n",
      "CPU times: total: 9.59 s\n",
      "Wall time: 59.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res4 = evaluate(X_train4, X_test4, y_train4, y_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>best_parameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.737827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.737167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 500}</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.737167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.729206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'uniform'}</td>\n",
       "      <td>0.725352</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.721158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.714954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}</td>\n",
       "      <td>0.725352</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.714668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            classifier  \\\n",
       "1          Naive Bayes   \n",
       "4        Random Forest   \n",
       "5             CatBoost   \n",
       "2  Logistic Regression   \n",
       "0                  kNN   \n",
       "6              XGBoost   \n",
       "3        Decision Tree   \n",
       "\n",
       "                                                                       best_parameters  \\\n",
       "1                                                                                   {}   \n",
       "4  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}   \n",
       "5                        {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 500}   \n",
       "2                                    {'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}   \n",
       "0                                             {'n_neighbors': 7, 'weights': 'uniform'}   \n",
       "6                         {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}   \n",
       "3                      {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}   \n",
       "\n",
       "   accuracy  precision    recall  f1_score  \n",
       "1  0.732394   0.578947  0.702128  0.737827  \n",
       "4  0.739437   0.613636  0.574468  0.737167  \n",
       "5  0.739437   0.613636  0.574468  0.737167  \n",
       "2  0.732394   0.604651  0.553191  0.729206  \n",
       "0  0.725352   0.595238  0.531915  0.721158  \n",
       "6  0.718310   0.581395  0.531915  0.714954  \n",
       "3  0.725352   0.611111  0.468085  0.714668  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(res4.sort_values(by=\"f1_score\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.737827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.737167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.737167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.729206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.725352</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.721158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.714954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.725352</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.714668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            classifier  accuracy  precision    recall  f1_score\n",
       "1          Naive Bayes  0.732394   0.578947  0.702128  0.737827\n",
       "4        Random Forest  0.739437   0.613636  0.574468  0.737167\n",
       "5             CatBoost  0.739437   0.613636  0.574468  0.737167\n",
       "2  Logistic Regression  0.732394   0.604651  0.553191  0.729206\n",
       "0                  kNN  0.725352   0.595238  0.531915  0.721158\n",
       "6              XGBoost  0.718310   0.581395  0.531915  0.714954\n",
       "3        Decision Tree  0.725352   0.611111  0.468085  0.714668"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    res4[[\"classifier\", \"accuracy\", \"precision\", \"recall\", \"f1_score\"]].sort_values(\n",
    "        by=\"f1_score\", ascending=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
